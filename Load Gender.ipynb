{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import cvlib as cv\n",
    "from keras.preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('D:\\\\GenderDetection\\\\gender_detection.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99999976\n",
      "0.00000057\n",
      "0\n",
      "man\n",
      "//\\\\\n",
      "0.00000000\n",
      "1.00000000\n",
      "1\n",
      "woman\n",
      "//\\\\\n"
     ]
    }
   ],
   "source": [
    "classes = ['man','woman']\n",
    "\n",
    "\n",
    "img = cv2.imread('D:\\\\GenderDetection\\\\two.jpg') \n",
    "img = cv2.resize(img, (1000, 400)) \n",
    "# apply face detection\n",
    "face, confidence = cv.detect_face(img)\n",
    "\n",
    "for idx, f in enumerate(face):\n",
    "    # get corner points of face rectangle        \n",
    "    (startX, startY) = f[0], f[1]\n",
    "    (endX, endY) = f[2], f[3]\n",
    "\n",
    "    # draw rectangle over face\n",
    "    cv2.rectangle(img, (startX,startY), (endX,endY), (0,255,0), 2)\n",
    "\n",
    "    # crop the detected face region\n",
    "    face_crop = np.copy(img[startY:endY,startX:endX])\n",
    "\n",
    "\n",
    "    # preprocessing of data for the model\n",
    "    face_crop = cv2.resize(face_crop, (50,50))\n",
    "    face_crop = face_crop.astype(\"float\") / 255.0\n",
    "    face_crop = img_to_array(face_crop)\n",
    "    face_crop = np.expand_dims(face_crop, axis=0)\n",
    "    \n",
    "    # apply gender detection on face\n",
    "    cf = model.predict(face_crop)[0] # model.predict return a 2D matrix\n",
    "    for i in cf:\n",
    "        print (\"%.8f\" % (i))\n",
    "    idx = np.argmax(cf)  #argmax get index of max value in cf [1.0,0.002]\n",
    "    print(idx)\n",
    "    label = classes[idx]\n",
    "    print(label)\n",
    "    print('//\\\\\\\\')\n",
    "    label = \"{}: {:.2f}%\".format(label, cf[idx] * 100)\n",
    "\n",
    "    Y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "\n",
    "        # write label and confidence above face rectangle\n",
    "    cv2.putText(img, label, (startX, Y),  cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.7, (0, 255, 0), 2)\n",
    "\n",
    "    # display output\n",
    "cv2.imshow(\"GenderDetection\", img)\n",
    "#cv2.imwrite('D:\\\\GenderDetection\\\\afterDetect.jpg', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
